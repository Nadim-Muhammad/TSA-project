---
title: "Rmarkdown project"
author: "Nadim Muhammad & Micha≈Ç Kulbat"
date: "2023-05-25"
output: html_document
html:
    css: styles.css
    toc: true
    toc-depth: 2
    toc-expand: 3
    toc-title: Contents
    toc-location: body
---

**Importing the libraries**

```{r message=FALSE, warning=FALSE}
library(xts)
library(lmtest)
library(quantmod)
library(dplyr)
library(fUnitRoots)
library(vars)
library(tseries)
library(aTSA)
library(car)
library(seasonal)
library(forecast)
library(kableExtra)
library(formattable)
library(Metrics)
library(TSEwgt)
library(tidyverse)
```

############################################################### 

# 1.Getting data

```{r}
setwd("C:/Users/micha/OneDrive/Dokumenty/GitHub/TSA-project/")

options(scipen = 10)

source("functions/function_plot_ACF_PACF_resids.R") 
source("functions/testdf.R")

data <- read.csv("data/TSA_2023_project_data_1.csv")

data_train <- data[1:970,]

data_test <- data[971:1000,]

data_train$X <- as.Date(data_train$X, format = "%Y-%m-%d")

data_test$X <- as.Date(data_test$X, format = "%Y-%m-%d")
```

**Let's also transform the `data.frame` into an `xts` object**

```{r}
data_train_xts <- xts(data_train[, -1], order.by = data_train$X)

data_test_xts <- xts(data_test[, -1], order.by = data_test$X)
```

# 2.Choosing time series

```{r}
plot(data_train_xts, col = c("black", "blue", "red", "purple", "green", "pink", "brown", "cyan", "magenta", "coral"), major.ticks = "years", grid.ticks.on = "years", grid.ticks.lty = 3, main = "Plotted time series", legend.loc = "bottomleft")
```

*BG test - null hypothesis: no serial correlation of any order (up to max.augmentations)*

*ADF test - null hypothesis: unit root in the time series*

```{r warning=FALSE}
for (i in 1:10) { 
print(i) 
print(testdf(variable = data_train_xts[,i], 
             max.augmentations = 3)) 
  } 
#-4


```

```{r warning=FALSE}
data_train_xts_diff <- diff.xts(data_train_xts)

for (i in 1:10) {
  print(i)
  print(testdf(variable = data_train_xts_diff[,i],
               max.augmentations = 3))
}
#1 3 4 9

```

```{r}
data_train_xts_diff <- diff.xts(data_train_xts)


chosen_ones <- xts(order.by = data_train$X)

chosen_ones$first<- data_train_xts[,3] 
chosen_ones$second<- data_train_xts[,9]

plot(chosen_ones)
```

first testdf(variable = chosen_ones\$first, max.augmentations = 3)

```{r}
chosen_ones$diff_first <- diff.xts(chosen_ones$first) 
chosen_ones$diff_second <- diff.xts(chosen_ones$second)
```

```{r warning=FALSE}
testdf(variable = chosen_ones$first, max.augmentations = 3)
```

second testdf(variable = chosen_ones\$second, max.augmentations = 3)

```{r warning=FALSE}
testdf(variable = chosen_ones$diff_second, max.augmentations = 3)
```

Both series integrated of order one (I(1))

############################################################### 

## 2.1 Checking for cointegration relation

```{r}
cointegration <- lm(first ~ second, data = chosen_ones)

summary(cointegration)
```

```{r warning=FALSE}
testdf(variable = residuals(cointegration), max.augmentations = 3)
```

```{r}
cointegration <- lm(first ~ second, data = chosen_ones)

summary(cointegration)

```

```{r warning=FALSE}
testdf(variable = residuals(cointegration), max.augmentations = 3)
```

#Coefficients: \# Estimate Std. Error t value Pr(\>\|t\|)\
\#(Intercept) 152.195497 0.107127 1420.7 \<2e-16 ***\# second -0.271123 0.002145 -126.4 \<2e-16*** \# The cointegrating vector is: 1, -152.195497, 0.271123 \# which defines the cointegrating relationship as: \# residuals = 1 \* first - 152.195497 + 0.271123 \* second

```{r}
cointegrated_series <- lag.xts(residuals(cointegration))

chosen_ones$lag_resid_coint <- cointegrated_series

plot(cointegrated_series)
```

```{r warning=FALSE}
testdf(variable = cointegrated_series, max.augmentations = 3)
```

############################################################# 

# 3 ARIMA models

############################################################### 

## 3.1 ARIMA for first time series (from before we know that this series is I(1))

```{r}
acf(chosen_ones$diff_first,
    lag.max = 36, # max lag for ACF
    ylim = c(-0.1, 0.1),   # limits for the y axis - we give c(min, max)
    lwd = 5,               # line width
    col = "dark green",
    na.action = na.pass)   # do not stop if there are missing values in the data
par(mfrow = c(2, 1))

```

```{r}
pacf(chosen_ones$diff_first, 
     lag.max = 36, 
     lwd = 5, col = "dark green",
     na.action = na.pass)
par(mfrow = c(1, 1))
```

looks like we should use ARIMA(7,1,x)

### ARIMA(1,1,1)

```{r}
arima111 <- Arima(chosen_ones$first, order = c(1, 1, 1))

coeftest(arima111)
par(mar = c(1, 1, 1, 1))
plot_ACF_PACF_resids(arima111)

```

ACF and PACF plots shows that some lags are still significant

```{r message=FALSE, warning=FALSE}
bj_pvalues = c()
for(i in c(1:100)){
  bj = Box.test(resid(arima111), type = "Ljung-Box", lag = i)
  bj_pvalues = append(bj_pvalues,bj$p.value)
}
plot(bj_pvalues, type='l')
abline(h=0.05, col='red', type='l')
```

The residuals are not white noise

### ARIMA(7,1,3)

```{r}
arima713 <- Arima(chosen_ones$first, 
                  order = c(7, 1, 3), 
                  include.constant = TRUE,
                  optim.control = list(maxit = 800),
                  optim.method = "L-BFGS-B")

arima713

coeftest(arima713)
```

only ar7 and ma1 are statistically insignificant (and drift)

```{r}
par(mar = c(1, 1, 1, 1))
plot_ACF_PACF_resids(arima713)
```

lags 15, 21 still significant

```{r message=FALSE, warning=FALSE}
bj_pvalues = c()
for(i in c(1:100)){
  bj = Box.test(resid(arima713), type = "Ljung-Box", lag = i)
  bj_pvalues = append(bj_pvalues,bj$p.value)
}
plot(bj_pvalues, type='l')
abline(h=0.05, col='red', type='l')
```

residuals are white noise

### ARIMA(7,1,15)

```{r}
arima7115 <- Arima(chosen_ones$first, order = c(7, 1, 15))

arima7115

coeftest(arima7115)
```

ar3, ar5 and ma7 and ma15 are statistically significant

```{r}
par(mar = c(1, 1, 1, 1))
plot_ACF_PACF_resids(arima7115)
```

lags 26 is on significance line

```{r message=FALSE, warning=FALSE}
bj_pvalues = c()
for(i in c(1:100)){
  bj = Box.test(resid(arima7115), type = "Ljung-Box", lag = i)
  bj_pvalues = append(bj_pvalues,bj$p.value)
}
plot(bj_pvalues, type='l')
abline(h=0.05, col='red', type='l')
```

residuals are white noise

### ARIMA(7,1,26)

```{r}
arima7126 <- Arima(chosen_ones$first, 
                    order = c(7, 1, 26),
                    include.constant = TRUE,
                    optim.control = list(maxit = 800),
                    optim.method = "L-BFGS-B")

coeftest(arima7126)
```

ar1, ar2, ar4, ar5, ar6 and ma3 statistically significant

```{r}
par(mar = c(1, 1, 1, 1))
plot_ACF_PACF_resids(arima7126)
```

lag 26 is significant, lets leave it for now

```{r}
bj_pvalues = c()
for(i in c(1:100)){
  bj = Box.test(resid(arima7126), type = "Ljung-Box", lag = i)
  bj_pvalues = append(bj_pvalues,bj$p.value)
}
plot(bj_pvalues, type='l')
abline(h=0.05, col='red', type='l')
```

residuals are white noise

**Now lets use previous models but lets set nonsignificant variables to 0 (arima713fixed but without last ar term)**

```{r}
arima613fixed <- Arima(chosen_ones$first,
                    order = c(6, 1, 3),
                    fixed = c(NA, NA, NA, NA, NA, NA,
                              0, NA, NA))

coeftest(arima613fixed)
```

nothing expect ar1 is significant

```{r}
par(mar = c(1, 1, 1, 1))
plot_ACF_PACF_resids(arima613fixed)
```

we still have some other lags significant

```{r}
bj_pvalues = c()
for(i in c(1:100)){
  bj = Box.test(resid(arima613fixed), type = "Ljung-Box", lag = i)
  bj_pvalues = append(bj_pvalues,bj$p.value)
}
plot(bj_pvalues, type='l')
abline(h=0.05, col='red', type='l')
```

**residuals are not a white noise!!!**

### arima7115 with nonsignificant variables set to 0 (expect ma10) (its arima5115)

```{r}
arima5115fixed <- Arima(chosen_ones$first,
                       order = c(5, 1, 15),
                       fixed = c(0, 0, NA, 0, NA,
                                 0,0,0,0,0,0,NA,0,0,NA,0,0,0,0,NA))                                 

coeftest(arima5115fixed)
```

everything is significant

```{r}
par(mar = c(1, 1, 1, 1))
plot_ACF_PACF_resids(arima5115fixed)
```

we still have some other lags significant

```{r}
bj_pvalues = c()
for(i in c(1:100)){
  bj = Box.test(resid(arima5115fixed), type = "Ljung-Box", lag = i)
  bj_pvalues = append(bj_pvalues,bj$p.value)
}
plot(bj_pvalues, type='l')
abline(h=0.05, col='red', type='l')
```

residuals are not white noise!!!!

### lets try arima7126 with nonsignificant variables set to 0 (its arima614) lets include ma2 and ma4

```{r}
arima614fixed <- Arima(chosen_ones$first,
                       order = c(6, 1, 4),
                       fixed = c(NA, NA, 0, NA, NA, NA,
                                 0,NA,NA,NA))                                 

coeftest(arima614fixed)
```

ar4 and ma4 are not significant

```{r}
par(mar = c(1, 1, 1, 1))
plot_ACF_PACF_resids(arima614fixed)
```

lag 15,20,21,26 on significance line

```{r}
bj_pvalues = c()
for(i in c(1:100)){
  bj = Box.test(resid(arima614fixed), type = "Ljung-Box", lag = i)
  bj_pvalues = append(bj_pvalues,bj$p.value)
}
plot(bj_pvalues, type='l')
abline(h=0.05, col='red', type='l')
```

residuals are white noise

### lets set to 0 nonsignificant variables from previous model (its arima 613 now)

```{r}
arima613fixed <- Arima(chosen_ones$first,
                        order = c(6, 1, 3),
                        fixed = c(NA, NA, 0, 0, NA, NA,
                                  0, NA, NA))                                 

coeftest(arima613fixed)
```

everything significant

```{r}
par(mar = c(1, 1, 1, 1))
plot_ACF_PACF_resids(arima613fixed)
```

lag 4, 15, 20, 21 and 26 on line

```{r}
bj_pvalues = c()
for(i in c(1:100)){
  bj = Box.test(resid(arima613fixed), type = "Ljung-Box", lag = i)
  bj_pvalues = append(bj_pvalues,bj$p.value)
}
plot(bj_pvalues, type='l')
abline(h=0.05, col='red', type='l')
```

residuals are white noise

### lets add AR(4) to the last model

```{r}
arima613fixed2 <- Arima(chosen_ones$first,
                       order = c(6, 1, 3),
                       fixed = c(NA, NA, 0, NA, NA, NA,
                                 0, NA, NA))                                 

coeftest(arima613fixed2)
```

everything significant

```{r}
par(mar = c(1, 1, 1, 1))
plot_ACF_PACF_resids(arima613fixed2)
```

lag 15, 20, 21 on line

```{r}
bj_pvalues = c()
for(i in c(1:100)){
  bj = Box.test(resid(arima613fixed2), type = "Ljung-Box", lag = i)
  bj_pvalues = append(bj_pvalues,bj$p.value)
}
plot(bj_pvalues, type='l')
abline(h=0.05, col='red', type='l')
```

residuals are white noise

# 4 INFORMATION CRITERIAS

```{r}
AIC(arima111, arima713, arima7115, arima7126,
    arima613fixed, arima613fixed2, arima614fixed, arima5115fixed)

BIC(arima111, arima713, arima7115, arima7126,
    arima613fixed, arima613fixed2, arima614fixed, arima5115fixed)

arima613fixed2
coeftest(arima613fixed2)
```

**Lets forecast 3 models with the lowest AIC arima613fixed2, arima713, arima614fixed**

```{r}
arima613fixed2_forecast <- forecast(arima613fixed2, h=30)
arima613fixed2_forecast

arima613fixed2_forecast_data <- data.frame(f_mean  = as.numeric(arima613fixed2_forecast$mean),
                                           f_lower = as.numeric(arima613fixed2_forecast$lower[, 2]),
                                           f_upper = as.numeric(arima613fixed2_forecast$upper[, 2]))

arima613fixed2_forecast_data_xts <- xts(arima613fixed2_forecast_data, order.by = data_test$X)
```

```{r}
arima713_forecast <- forecast(arima713, h=30)
arima713_forecast

arima713_forecast_data <- data.frame(f_mean  = as.numeric(arima713_forecast$mean),
                                     f_lower = as.numeric(arima713_forecast$lower[, 2]),
                                     f_upper = as.numeric(arima713_forecast$upper[, 2]))

arima713_forecast_data_xts <- xts(arima713_forecast_data, order.by = data_test$X)
```

```{r}
arima614fixed_forecast <- forecast(arima614fixed, h=30)
arima614fixed_forecast

arima614fixed_forecast_data <- data.frame(f_mean  = as.numeric(arima614fixed_forecast$mean),
                                          f_lower = as.numeric(arima614fixed_forecast$lower[, 2]),
                                          f_upper = as.numeric(arima614fixed_forecast$upper[, 2]))

arima614fixed_forecast_data_xts <- xts(arima614fixed_forecast_data, order.by = data_test$X)
```

# 5 Forecast visualization

```{r}
data_all_xts <- rbind(data_train_xts[,3], data_test_xts[,3])
names(data_all_xts) <- "first"

ARIMA_forecasts_first <- merge(data_all_xts,
                               arima613fixed2_forecast_data_xts,
                               arima713_forecast_data_xts,
                               arima614fixed_forecast_data_xts)
names(ARIMA_forecasts_first) <- c("Time Series", "arima613 mean", "arima613 95% lower", "arima613 95% upper", "arima713 mean", "arima713 95% lower", "arima713 95% upper", "arima614 mean", "arima614 95% lower", "arima614 95% upper")

plot(ARIMA_forecasts_first["2020-11/",], 
     major.ticks = "years", 
     grid.ticks.on = "years",
     grid.ticks.lty = 3,
     main = "30 day forecast of chosen time series",
     col = c("black", "blue", "red", "red", "green", "pink", "pink", "cyan", "magenta", "magenta"),
     legend.loc = "topleft")
```

# 6 ARIMA for second time series (from before we know that this series is I(1))

```{r}
par(mfrow = c(2, 1)) 
acf(chosen_ones$diff_second,
    lag.max = 36, # max lag for ACF
    ylim = c(-0.1, 0.1),   # limits for the y axis - we give c(min, max)
    lwd = 5,               # line width
    col = "dark green",
    na.action = na.pass)   # do not stop if there are missing values in the data
pacf(chosen_ones$diff_second, 
     lag.max = 36, 
     lwd = 5, col = "dark green",
     na.action = na.pass)
par(mfrow = c(1, 1))
```

### lets start with checking ARIMA(1,1,1) and ARIMA(3,1,3)

### ARIMA(1,1,1)

```{r}
arima111_second <- Arima(chosen_ones$second, order = c(1, 1, 1))

coeftest(arima111_second)
```

all variables significant

```{r}
plot_ACF_PACF_resids(arima111_second)
```

ACF and PACF plots shows that some lags are still significant

```{r}
bj_pvalues = c()
for(i in c(1:100)){
  bj = Box.test(resid(arima111_second), type = "Ljung-Box", lag = i)
  bj_pvalues = append(bj_pvalues,bj$p.value)
}
plot(bj_pvalues, type='l')
abline(h=0.05, col='red', type='l')
```

residuals are not white noise

### ARIMA(3,1,3)

```{r}
arima313_second <- Arima(chosen_ones$second, order = c(3, 1, 3))

coeftest(arima313_second)
```

ma3 not significant

```{r}
plot_ACF_PACF_resids(arima313_second)
```

lags 15, 18, 20 are still significant

```{r}
bj_pvalues = c()
for(i in c(1:100)){
  bj = Box.test(resid(arima313_second), type = "Ljung-Box", lag = i)
  bj_pvalues = append(bj_pvalues,bj$p.value)
}
plot(bj_pvalues, type='l')
abline(h=0.05, col='red', type='l')
```

residuals are white noise

### ARIMA(15,1,3)

```{r}
arima1513_second <- Arima(chosen_ones$second, order = c(15, 1, 3))

coeftest(arima1513_second)
```

ar1, ar2, ar3, ar4, ar8, ar15, ma1, ma3 significant

```{r}
plot_ACF_PACF_resids(arima1513_second)
```

lags 17, 20, 26 are still significant

```{r}
bj_pvalues = c()
for(i in c(1:100)){
  bj = Box.test(resid(arima1513_second), type = "Ljung-Box", lag = i)
  bj_pvalues = append(bj_pvalues,bj$p.value)
}
plot(bj_pvalues, type='l')
abline(h=0.05, col='red', type='l')
```

residuals are white noise

### Checking previous models, but without insignificant variables

### ARIMA(3,1,3) without ma3 = ARIMA(3,1,2)

```{r}
arima312_second <- Arima(chosen_ones$second, order = c(3, 1, 2))

coeftest(arima312_second)
```

everything significant

```{r}
plot_ACF_PACF_resids(arima312_second)
```

lags 15, 18, 20, 26 are still significant

```{r}
bj_pvalues = c()
for(i in c(1:100)){
  bj = Box.test(resid(arima312_second), type = "Ljung-Box", lag = i)
  bj_pvalues = append(bj_pvalues,bj$p.value)
}
plot(bj_pvalues, type='l')
abline(h=0.05, col='red', type='l')
```

residuals are most likely white noise

### ARIMA(15,1,3), but without insignificant variables

```{r}
arima1513_fixed_second <- Arima(chosen_ones$second,
                                order = c(15, 1, 3),
                                fixed = c(NA, NA, NA, NA, 0, 0, 0, NA, 0, 0, 0, 0, 0, 0, NA,
                                          NA, 0, NA))  

coeftest(arima1513_fixed_second)
```

ar1, ar4, ma1 not significant

```{r}
plot_ACF_PACF_resids(arima1513_fixed_second)
```

lag 20 is still significant, lag 6 and 17 on line

```{r}
bj_pvalues = c()
for(i in c(1:100)){
  bj = Box.test(resid(arima1513_fixed_second), type = "Ljung-Box", lag = i)
  bj_pvalues = append(bj_pvalues,bj$p.value)
}
plot(bj_pvalues, type='l')
abline(h=0.05, col='red', type='l')
```

residuals are white noise

### ARIMA(15,1,3) fixed, but without insignificant variables

```{r}
arima1513_fixed2_second <- Arima(chosen_ones$second,
                                order = c(15, 1, 3),
                                fixed = c(0, NA, NA, 0, 0, 0, 0, NA, 0, 0, 0, 0, 0, 0, NA,
                                          0, 0, NA))  

coeftest(arima1513_fixed2_second)
```

everything significant

```{r}
plot_ACF_PACF_resids(arima1513_fixed2_second)
```

lags 1, 6, 20, 26 are still significant

```{r}
bj_pvalues = c()
for(i in c(1:100)){
  bj = Box.test(resid(arima1513_fixed2_second), type = "Ljung-Box", lag = i)
  bj_pvalues = append(bj_pvalues,bj$p.value)
}
plot(bj_pvalues, type='l')
abline(h=0.05, col='red', type='l')
```

residuals are white noise

# 4-2 INFORMATION CRITERIAS

```{r}
AIC(arima111_second, arima313_second, arima1513_second, arima1513_fixed_second, arima1513_fixed2_second)

BIC(arima111_second, arima313_second, arima1513_second, arima1513_fixed_second, arima1513_fixed2_second)
```

### choosing 3 with the lowest AIC - (arima1513_fixed_second, arima1513_fixed2_second, arima313_second)

```{r}
arima1513_fixed_second_forecast <- forecast(arima1513_fixed_second, h=30)
arima1513_fixed_second_forecast

arima1513_fixed_second_forecast_data <- data.frame(f_mean  = as.numeric(arima1513_fixed_second_forecast$mean),
                                           f_lower = as.numeric(arima1513_fixed_second_forecast$lower[, 2]),
                                           f_upper = as.numeric(arima1513_fixed_second_forecast$upper[, 2]))

arima1513_fixed_second_forecast_data_xts <- xts(arima1513_fixed_second_forecast_data, order.by = data_test$X)
```

```{r}
arima1513_fixed2_second_forecast <- forecast(arima1513_fixed2_second, h=30)
arima1513_fixed2_second_forecast

arima1513_fixed2_second_forecast_data <- data.frame(f_mean  = as.numeric(arima1513_fixed2_second_forecast$mean),
                                     f_lower = as.numeric(arima1513_fixed2_second_forecast$lower[, 2]),
                                     f_upper = as.numeric(arima1513_fixed2_second_forecast$upper[, 2]))

arima1513_fixed2_second_forecast_data_xts <- xts(arima1513_fixed2_second_forecast_data, order.by = data_test$X)
```

```{r}
arima313_second_forecast <- forecast(arima313_second, h=30)
arima313_second_forecast

arima313_second_forecast_data <- data.frame(f_mean  = as.numeric(arima313_second_forecast$mean),
                                          f_lower = as.numeric(arima313_second_forecast$lower[, 2]),
                                          f_upper = as.numeric(arima313_second_forecast$upper[, 2]))

arima313_second_forecast_data_xts <- xts(arima313_second_forecast_data, order.by = data_test$X)
```

# VISUALIZATION OF THE SECOND TIME SERIES

```{r}
data_all_second_xts <- rbind(data_train_xts[,9], data_test_xts[,9])
names(data_all_second_xts) <- "second"

ARIMA_forecasts_second <- merge(data_all_second_xts,
                               arima1513_fixed_second_forecast_data_xts,
                               arima1513_fixed2_second_forecast_data_xts,
                               arima313_second_forecast_data_xts)
names(ARIMA_forecasts_second) <- c("Second Time Series", "arima1513_fixed mean", "arima1513_fixed 95% lower", "arima1513_fixed 95% upper", "arima1513_fixed2 mean", "arima1513_fixed2 95% lower", "arima1513_fixed2 95% upper", "arima313 mean", "arima313 95% lower", "arima313 95% upper")

plot(ARIMA_forecasts_second["2020-11/",], 
     major.ticks = "years", 
     grid.ticks.on = "years",
     grid.ticks.lty = 3,
     main = "30 day forecast of chosen time series",
     col = c("black", "blue", "red", "red", "green", "pink", "pink", "cyan", "magenta", "magenta"),
     legend.loc = "bottomleft")
```

# ECM and VECM

```{r}
ecm_model <- lm(diff_first ~ diff_second + lag_resid_coint, data = chosen_ones)
```

delete the intercept

```{r}
ecm_model <- lm(diff_first ~ diff_second + lag_resid_coint -1, data = chosen_ones)

summary(ecm_model)
```

diff_second is not statistically significant, but lets leave it

The parameter -0.03568 describes a short term relationship between `first` and `second`, so if `second` increases by 1 then the `first` in the *short run* will decrease by 0.03568.

The *long run* relationship is described by the parameter 0.271123 from the cointegrating relationship: so if `ppi` increases by 1 in the LONG RUN `cpi` will increase by 0.271123.

The value of -0.55365 is the estimate of the *adjustment coefficient*. As expected, its sign is negative and this value means that about 55.37% of the unexpected error (increase in gap) will be corrected in the next period, so any unexpected deviation should be corrected finally on average within about 1.8 periods.

# GRANGER CAUSALITY TEST

```{r}
grangertest(first ~ second,
            data = chosen_ones,
            order = 3)
```

second causes first (we rejected null hypothesis about no causality)

```{r}
grangertest(second ~ first,
            data = chosen_ones,
            order = 3)
```

first causes second (we rejected null hypothesis about no causality)

```{r}
for(i in 1:5){
  print(i)
  print("first ~ second")
  print(grangertest(first ~ second,
                    data = chosen_ones,
                    order = i))
  print(i)
  print("second ~ first")
  print(grangertest(second ~ first,
              data = chosen_ones,
              order = i))
}
```

**Conclusion** - we have bi-directional feedback in all cases

# VAR MODELS

### Select VAR model with proper lag legnht

```{r}
VARselect(chosen_ones[,1:2], lag.max = 10) %>%
  .$criteria %>% 
  t() %>% 
  as_tibble() %>% 
  mutate(nLags = 1:nrow(.)) %>%
  kbl(digits = 3) %>%
  kable_classic("striped", full_width = F)
```

6 lags are the best according to all information criterias

### Check IC with seasonal VAR

```{r}
VARselect(chosen_ones[,1:2], lag.max = 10, season = 31) %>%
  .$criteria %>% 
  t() %>% 
  as_tibble() %>% 
  mutate(nLags = 1:nrow(.)) %>%
  kbl(digits = 3) %>%
  kable_classic("striped", full_width = F)
```

All but one (FPE IC) shows that 6 lags are the best

With ACF and PACF we showed that there is no seasonality detected

## Check season = 31, 30, 7

```{r}
VAR_model_6_lags <- VAR(chosen_ones[,1:2],
                        p = 6,
                        season = 31)

summary(VAR_model_6_lags)
```

only sd10 in first is on the line of significance

```{r}
VAR_model_6_lags <- VAR(chosen_ones[,1:2],
                        p = 6,
                        season = 30)

summary(VAR_model_6_lags)
```

only sd12 in first is on the line of significance

```{r}
VAR_model_6_lags <- VAR(chosen_ones[,1:2],
                        p = 6,
                        season = 7)

summary(VAR_model_6_lags)
```

only sd3 in first is statistically significant

```{r}
VAR_model_6_lags <- VAR(chosen_ones[,1:2],
                        p = 6)

summary(VAR_model_6_lags)
```

Some variables are not significant, but in general all lag orders have some significant part

```{r}
plot(VAR_model_6_lags)
```

ACF and PACF for first looks good, but for second both ACF and PACF have lag 8 on the line so lets make a model with 8 lags

```{r}
VAR_model_8_lags <- VAR(chosen_ones[,1:2],
                        p = 8)

summary(VAR_model_8_lags)
```

lags 7 and 8 are not significant

```{r}
plot(VAR_model_8_lags)
```

ACF and PACF in both cases looks good

**lets look at the residuals**

```{r}
serial.test(VAR_model_6_lags)

serial.test(VAR_model_8_lags)
```

Both models show no autocorrelation in residuals

## AIC/BIC

```{r}
AIC(VAR_model_6_lags, VAR_model_8_lags)
BIC(VAR_model_6_lags, VAR_model_8_lags)
```

AIC prefers model with 8 lags, but BIC prefers model with 6 lags, lets stick to 6 lags, because as we showed earlier adding more lags gives us nonsignificant variables

## IRF

```{r}
plot(irf(VAR_model_6_lags, n.ahead = 36))
```

## FEVD

```{r}
plot(fevd(VAR_model_6_lags, n.ahead = 36))
```

## JOHANSON COINTEGRATION TEST

```{r}
johan.test.trace <- 
  ca.jo(chosen_ones[,1:2],
        ecdet = "trend",
        type = "trace",  # type of the test: trace or eigen
        K = 6) # lags in VAR model
summary(johan.test.trace)

cbind(summary(johan.test.trace)@teststat, summary(johan.test.trace)@cval)
```

exactly one cointegrated vector

## change type to eigen

```{r}
johan.test.eigen <- 
  ca.jo(chosen_ones[,1:2],
        ecdet = "trend",
        type = "eigen",  # type of the test: trace or eigen
        K = 6) # lags in VAR model
summary(johan.test.eigen)

cbind(summary(johan.test.eigen)@teststat, summary(johan.test.eigen)@cval)
```

same interpretation

# VECM

```{r}
VECM_model <- cajorls(johan.test.trace, # defined specification
                                     r = 1) # number of cointegrating vectors

summary(VECM_model$rlm)
```

only etc1 not significant in first equation

```{r}
VECM_model$beta
```

We can reparametrize the VEC model into VAR 
(here we use the specification object):

```{r}
VECM_model.asVAR <- vec2var(johan.test.trace, r = 1)
```

**Check the results**

```{r}
VECM_model.asVAR
```

Based on the reparametrized model, we can calculate and plot Impulse Response Functions:

```{r}
plot(irf(VECM_model.asVAR, n.ahead = 36))
```

We can also perform variance decomposition:

```{r}
plot(fevd(VECM_model.asVAR, n.ahead = 36))
```

The results are pretty similar to the earlier `VAR(6)` model.

Let's also check if model residuals are autocorrelated.

Residuals can be extracted only from the VAR reparametrized model.

```{r}
head(residuals(VECM_model.asVAR))
serial.test(VECM_model.asVAR)
```

The null is not rejected, residuals are not autocorrelated.

You can see the ACF and PACF functions by plotting the results of the `serial.test()`

```{r}
plot(serial.test(VECM_model.asVAR))
```

8 lag in PACF of residuals and squared Residuals in second model seems significant

lets plot EDF (Empirical Distribution Function) better

```{r}
VECM_model.asVAR %>%
  residuals() %>%
  as_tibble() %>%
  ggplot(aes(`resids of first`)) +
  geom_histogram(aes(y =..density..),
                 colour = "black", 
                 fill = "pink") +
  stat_function(fun = dnorm, 
                args = list(mean = mean(residuals(VECM_model.asVAR)[, 1]), 
                            sd = sd(residuals(VECM_model.asVAR)[, 1]))) +
  theme_bw() + 
  labs(
    title = "Density of PPI residuals", 
    y = "", x = "",
    caption = "source: own calculations"
  )
```

```{r}
VECM_model.asVAR %>%
  residuals() %>%
  as_tibble() %>%
  ggplot(aes(`resids of second`)) +
  geom_histogram(aes(y =..density..),
                 colour = "black", 
                 fill = "pink") +
  stat_function(fun = dnorm, 
                args = list(mean = mean(residuals(VECM_model.asVAR)[, 2]), 
                            sd = sd(residuals(VECM_model.asVAR)[, 2]))) +
  theme_bw() + 
  labs(
    title = "Density of CPI residuals", 
    y = "", x = "",
    caption = "source: own calculations"
  )
```

#### Use Jarque-Bera multivariate test to check for normality in residuals

```{r}
normality.test(VECM_model.asVAR)
```

null about normality is **not rejected!!!**

```{r}
VECM_model.asVAR.fore <- 
  predict(
    VECM_model.asVAR,     # no of cointegrating vectors 
    n.ahead = 30, # forecast horizon
    ci = 0.95)
```

# VECM forecasts for *first*:

```{r}
VECM_model.asVAR.fore$fcst$first
```

# VECM forecasts for *second*:

```{r}
VECM_model.asVAR.fore$fcst$second
```

### Forecasts
```{r}
VECM_first_forecast <- xts(VECM_model.asVAR.fore$fcst$first[,-4], order.by = data_test$X)

VECM_second_forecast <- xts(VECM_model.asVAR.fore$fcst$second[,-4], order.by = data_test$X)


names(VECM_first_forecast) <- c("first_fore", "first_lower", "first_upper")

names(VECM_second_forecast) <- c("second_fore", "second_lower", "second_upper")


VECM_first_all_data <- merge(data_all_xts,
                             data_all_second_xts,
                             VECM_first_forecast,
                             VECM_second_forecast)

plot(VECM_first_all_data["2020-11/", c("first", "first_fore",
                        "first_lower", "first_upper")], 
     major.ticks = "years", 
     grid.ticks.on = "years",
     grid.ticks.lty = 3,
     main = "30 days forecast of first",
     col = c("black", "blue", "red", "red"))

plot(VECM_first_all_data["2020-11/", c("second", "second_fore",
                        "second_lower", "second_upper")], 
     major.ticks = "years", 
     grid.ticks.on = "years",
     grid.ticks.lty = 3,
     main = "30 days forecast of second",
     col = c("black", "blue", "red", "red"))
```

# WITH ARIMA MODELS

```{r}
forecasts_first_all <- merge(ARIMA_forecasts_first,
                             VECM_first_forecast)

forecasts_second_all <- merge(ARIMA_forecasts_second,
                             VECM_second_forecast)
```

### First

```{r}
plot(forecasts_first_all["2020-11/",], 
     major.ticks = "years", 
     grid.ticks.on = "years",
     grid.ticks.lty = 3,
     main = "30 day forecast of chosen time series",
     col = c("black", "blue", "red", "red", "green", "pink", "pink", "cyan", "magenta", "magenta", "orange", "yellow", "yellow"),
     legend.loc = "bottomleft")
```

#Second
```{r}
plot(forecasts_second_all["2020-11/",], 
     major.ticks = "years", 
     grid.ticks.on = "years",
     grid.ticks.lty = 3,
     main = "30 day forecast of chosen time series",
     col = c("black", "blue", "red", "red", "green", "pink", "pink", "cyan", "magenta", "magenta", "orange", "yellow", "yellow"),
     legend.loc = "bottomleft")
```

# EX POST ERRORS

```{r}
names(forecasts_first_all)

names(forecasts_second_all)
```

